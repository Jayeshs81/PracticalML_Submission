---
title: "Predicting How Well an Activity was Performed"
author: "Jayesh Samant"
date: "January 16, 2017"
output: html_document
---

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
library(dplyr)
library(tree)
library(randomForest)
library(ggplot2)
```

## Executive Summary

The objective of this paper is to predict how well an activity was performed using the data collected from the  accelerometers on the belt, forearm, arm, and dumbell. To perform this analysis we first load and transform the training data set to include only the relevant columns. We then build a simple classification tree to aid in the inference and then build a prediction tree using random forest algorithm. We use the random forest model to predict the outcome on the test data.

## Data Loading

We first download the training and the test data from the provided locations. The training and test data frames are then loaded into memory.

```{r cache=TRUE}
## Download the training and the test data
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "training_data.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "testing_data.csv")

## Load the training and test data frames into memory
training <- read.csv("training_data.csv")
testing <- read.csv("testing_data.csv")
```

The training data set is composed of `r nrow(training)` rows and `r ncol(training)` columns. While the test data set of composed of `r nrow(testing)` rows and `r ncol(testing)` columns.

## Data Transformation

The training dataset contains a number of columns in which almost 97% of the values are NA. We first identify such columns and then eliminate them from the model building exercise.
```{r}
## countnas identifies the proportion of entries in its arguments which are NA
countnas <- function(x) { sum(is.na(x)) / length(x)}

## For each column in training determine the proportion of entries which are NA
result <- apply(training, 2, countnas) 
table(result)

## Include only the columns which have no NAs in the model building exercise
columns <- names(subset(result, result == 0))
training_final <- training[, columns]
```

The reduced training data set now has only `r ncol(training_final)` columns.  

However the reduced training dataset still contains a number of columns which contain a majority of blank values. There columns are of the form
* kurtosis_roll_  
* kurtosis_picth
* kurtosis_yaw  
* skewness_roll  
* skewness_yaw_  
* skewness_pitch  
* max_yaw  
* min_yaw  
* amplitude_yaw

We identify these columns and eliminate these from the training dataset.
```{r}
asFactors <- which(grepl("^kurtosis_roll_|^kurtosis_picth|^kurtosis_yaw|^skewness_roll|^skewness_roll_|^skewness_yaw_|^max_yaw|^min_yaw|^amplitude_yaw|^skewness_pitch", names(training_final)))
training_final <- training_final[,-asFactors]
```

The reduced training data set now has only `r ncol(training_final)` columns. 

We also eliminate the first seven columns of the training dataset. These columns refer to the record number, username, timestamps etc. which should not be part of the model.

```{r}
training_final <- training_final[,-(1:7)]
```

We use this training_final dataset with `r ncol(training_final)` columns for building the prediction model.

## Inference Model

We first build a simple model to draw some inferences on the data. We use the classification tree to create the simple model.

```{r}
infModel <- tree(classe~., data = training_final)
summary(infModel)
```

The five most important predictors are `r summary(infModel)$used[1:5]`. The model has `r summary(infModel)$size` leaf nodes. The total misclassification error rate for this model is `r round(summary(infModel)$misclass[1]/summary(infModel)$misclass[2]*100,2)`%. which is quite high.

The plot of the resulting classification tree is shown below.  
```{r fig.width=20, fig.height=10}
plot(infModel)
text(infModel)
```

we run some cross-validations on the training data to determine the optimum size of the classification tree.

```{r}
cvTree <- cv.tree(infModel, FUN = prune.misclass)
plot(cvTree$size, cvTree$dev, xlab = "Tree Size", ylab = "# of Miscalssifications", type="b")
```

We can see that the size of 18 return the minimum number of misclassifications and hence there is no further reason for pruning the tree.

## Prediction Model

With an training error rate of `r round(summary(infModel)$misclass[1]/summary(infModel)$misclass[2]*100,2)`%, the simple tree for inference performs badly for prediction. We hence use random forests to select the best prediction model.

```{r, cache=TRUE}
predModel <- randomForest(classe~., data = training_final)
predModel
```

Thre prediction model has an OOB error rate of 0.28%. This model is a large improvement over the simple inference model.

The below diagram shows the predictors considered in the model and their importance.
```{r}
varImpPlot(predModel)
```

## Test Set Prediction

```{r}
preds <- predict(predModel, newdata = testing)
```

The predictions on the twenty records in the test set are as follows:
`r preds`.
